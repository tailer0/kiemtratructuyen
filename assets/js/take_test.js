// Enhanced AI Proctoring System - ALL IN ONE
// Bao g·ªìm: AI Detect + Ch·∫∑n chu·ªôt/Ph√≠m/Tab + Popup C·∫£nh b√°o

// --- BI·∫æN TO√ÄN C·ª§C ---
window.isSubmitting = false;

document.addEventListener('DOMContentLoaded', () => {
    // DOM Elements
    const timerElement = document.getElementById('timer');
    const webcamElement = document.getElementById('webcam');
    const statusBox = document.getElementById('status-box');
    const captureCanvas = document.getElementById('captureCanvas');
    const testForm = document.getElementById('test-form');
    const startButton = document.getElementById('start-test-button');
    const testContent = document.getElementById('test-content');
    const proctoringContainer = document.getElementById('proctoring-container');
    const startOverlay = document.getElementById('start-test-overlay');

    // AI Models
    let faceMeshModel;
    let cocoSsdModel = null;
    let videoInterval, objectDetectionInterval;

    // ============================================
    // 1. CONFIGURATION
    // ============================================
    const CONFIG = {
        face: {
            yawThreshold: 40, pitchDownThreshold: 30, pitchUpThreshold: 25,
            minViolationDuration: 2500, // 2.5s m·ªõi b·∫Øt l·ªói
            detectionInterval: 500,
        },
        noFace: { duration: 6000, warningDuration: 3000 },
        multipleFace: { duration: 4000 },
        object: { enabled: false, scanInterval: 2000 },
        logCooldown: 5000, // Gi√£n c√°ch log l·ªói (5s)
    };

    // ============================================
    // 2. STATE MANAGEMENT
    // ============================================
    const state = {
        face: { lastSeen: Date.now(), startTime: null },
        lastLogTime: {},
        calibration: { isCalibrated: false, samples: [], neutralYaw: 0, neutralPitch: 0 }
    };

    // ============================================
    // 3. SECURITY EVENTS (CH·∫∂N MOUSE, KEY, TAB)
    // ============================================
    function setupSecurityListeners() {
        console.log("üõ°Ô∏è ƒêang k√≠ch ho·∫°t l√° ch·∫Øn b·∫£o m·∫≠t...");

        // A. Ch·∫∑n chu·ªôt ph·∫£i
        document.addEventListener('contextmenu', event => {
            event.preventDefault();
            window.logCheating('right_click', 'C·ªë t√¨nh b·∫•m chu·ªôt ph·∫£i', null);
        });

        // B. Ch·∫∑n Copy/Paste/Cut
        ['copy', 'paste', 'cut'].forEach(evt => {
            document.addEventListener(evt, (e) => {
                e.preventDefault();
                window.logCheating('copy_paste', `Thao t√°c ${evt}`, null);
            });
        });

        // C. Ph√°t hi·ªán chuy·ªÉn Tab / Thu nh·ªè
        document.addEventListener("visibilitychange", () => {
            if (document.hidden) {
                window.logCheating('switched_tab', 'R·ªùi kh·ªèi m√†n h√¨nh thi', null);
            }
        });

        // D. Ph√°t hi·ªán click ra ngo√†i (M·∫•t focus)
        window.addEventListener("blur", () => {
            if (document.activeElement === document.body) {
                window.logCheating('window_blur', 'Click ra ngo√†i khu v·ª±c thi', null);
            }
        });

        // E. Ch·∫∑n ph√≠m c·∫•m (F12, Ctrl+P, PrintScreen...)
        document.addEventListener('keydown', function(e) {
            if (
                e.key === "F12" || 
                (e.ctrlKey && e.shiftKey && (e.key === "I" || e.key === "i" || e.key === "C" || e.key === "c")) ||
                (e.ctrlKey && (e.key === "p" || e.key === "P" || e.key === "u" || e.key === "U"))
            ) {
                e.preventDefault();
                window.logCheating('devtools_key_attempt', 'S·ª≠ d·ª•ng ph√≠m t·∫Øt c·∫•m', null);
            }
        });
    }

    // ============================================
    // 4. CAMERA & AI LOGIC
    // ============================================
    async function setupCamera() {
        try {
            statusBox.textContent = 'ƒêang kh·ªüi ƒë·ªông camera...';
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: { ideal: 640 }, height: { ideal: 480 } }, audio: false 
            });
            webcamElement.srcObject = stream;
            return new Promise(resolve => webcamElement.onloadedmetadata = () => resolve(webcamElement));
        } catch (error) {
            statusBox.textContent = "Kh√¥ng th·ªÉ truy c·∫≠p camera";
            return null;
        }
    }

    async function loadModels() {
        statusBox.textContent = 'ƒêang t·∫£i AI...';
        try {
            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
            const config = {
                runtime: 'mediapipe', solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
                maxFaces: 3, refineLandmarks: false
            };
            faceMeshModel = await faceLandmarksDetection.createDetector(model, config);
            
            // Load Object Detection ·∫©n (Lazy load)
            (async () => {
                try {
                    if (typeof cocoSsd !== 'undefined') {
                        cocoSsdModel = await cocoSsd.load();
                        CONFIG.object.enabled = true;
                    }
                } catch(e) {}
            })();

            statusBox.textContent = 'H·ªá th·ªëng s·∫µn s√†ng';
            return true;
        } catch (error) {
            statusBox.textContent = "L·ªói t·∫£i AI";
            alert("L·ªói t·∫£i AI Model. Vui l√≤ng t·∫£i l·∫°i trang.");
            return false;
        }
    }

    // --- AI: Face Logic ---
    async function detectFaces() {
        if (!faceMeshModel || !webcamElement || webcamElement.readyState < 2) return;
        
        try {
            const predictions = await faceMeshModel.estimateFaces(webcamElement, { flipHorizontal: false });

            // 1. Kh√¥ng th·∫•y m·∫∑t
            if (predictions.length === 0) {
                if (!state.face.startTime) state.face.startTime = Date.now();
                const duration = Date.now() - state.face.startTime;
                
                if (duration > CONFIG.noFace.warningDuration) statusBox.textContent = "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t";
                if (duration > CONFIG.noFace.duration && canLog('no_face_detected')) {
                    window.logCheating('no_face_detected', `M·∫•t m·∫∑t ${Math.round(duration/1000)}s`, captureFrame());
                }
                return;
            }
            state.face.startTime = null;

            // 2. Nhi·ªÅu ng∆∞·ªùi
            if (predictions.length > 1) {
                statusBox.textContent = `‚ö†Ô∏è Ph√°t hi·ªán ${predictions.length} ng∆∞·ªùi`;
                if (canLog('multiple_faces')) {
                    window.logCheating('multiple_faces', `Ph√°t hi·ªán ${predictions.length} ng∆∞·ªùi`, captureFrame());
                }
                return;
            }

            // 3. H∆∞·ªõng nh√¨n (Head Pose)
            const keypoints = predictions[0].keypoints;
            const pose = calculateHeadPose(keypoints);
            if (pose) analyzePose(pose);

        } catch (e) { console.error(e); }
    }

    // --- AI: Pose Calculation ---
    function calculateHeadPose(kp) {
        const nose = kp.find(p => p.name === 'noseTip');
        const leftCheek = kp.find(p => p.index === 234);
        const rightCheek = kp.find(p => p.index === 454);
        if(!nose || !leftCheek || !rightCheek) return null;

        const rangeX = Math.abs(leftCheek.x - rightCheek.x);
        const midX = (leftCheek.x + rightCheek.x) / 2;
        // Yaw: ƒê·ªô l·ªách c·ªßa m≈©i so v·ªõi trung t√¢m 2 m√°
        const yaw = ((nose.x - midX) / rangeX) * 100; // Gi√° tr·ªã t∆∞∆°ng ƒë·ªëi
        
        const eyeLine = (kp.find(p=>p.name==='leftEye').y + kp.find(p=>p.name==='rightEye').y)/2;
        const chin = kp.find(p=>p.index===152).y;
        const faceH = Math.abs(chin - eyeLine);
        // Pitch: ƒê·ªô cao m≈©i
        const pitch = ((nose.y - eyeLine) / faceH) * 100;

        return { yaw, pitch };
    }

    function analyzePose(pose) {
        // Auto Calibrate (L·∫•y m·∫´u v·ªã tr√≠ ng·ªìi ban ƒë·∫ßu)
        if (!state.calibration.isCalibrated) {
            state.calibration.samples.push(pose);
            if(state.calibration.samples.length > 20) {
                const avgY = state.calibration.samples.reduce((a,b)=>a+b.yaw,0)/20;
                const avgP = state.calibration.samples.reduce((a,b)=>a+b.pitch,0)/20;
                state.calibration.neutralYaw = avgY;
                state.calibration.neutralPitch = avgP;
                state.calibration.isCalibrated = true;
                statusBox.textContent = "‚úÖ ƒê√£ hi·ªáu chu·∫©n t∆∞ th·∫ø";
            } else {
                statusBox.textContent = `ƒêang hi·ªáu chu·∫©n... ${state.calibration.samples.length * 5}%`;
            }
            return;
        }

        const dy = pose.yaw - state.calibration.neutralYaw;
        const dp = pose.pitch - state.calibration.neutralPitch;

        let msg = '';
        let type = '';

        if (Math.abs(dy) > 25) { msg = "Quay m·∫∑t qu√° m·ª©c"; type = "looking_away"; }
        else if (dp > 20) { msg = "C√∫i ƒë·∫ßu xu·ªëng"; type = "head_down"; }
        else if (dp < -20) { msg = "Ng·∫©ng ƒë·∫ßu l√™n"; type = "head_up"; }

        if (msg) {
            statusBox.textContent = `‚ö†Ô∏è ${msg}`;
            if (canLog(type)) window.logCheating(type, msg, captureFrame());
        } else {
            if (statusBox.textContent.includes('‚ö†Ô∏è')) statusBox.textContent = "T∆∞ th·∫ø b√¨nh th∆∞·ªùng";
        }
    }

    // --- AI: Object Logic ---
    async function detectObjects() {
        if (!CONFIG.object.enabled || !cocoSsdModel) return;
        try {
            const predictions = await cocoSsdModel.detect(webcamElement);
            const phone = predictions.find(p => p.class === 'cell phone' && p.score > 0.6);
            if (phone) {
                statusBox.textContent = "‚ö†Ô∏è Ph√°t hi·ªán ƒëi·ªán tho·∫°i";
                if(canLog('phone_detected')) window.logCheating('phone_detected', 'S·ª≠ d·ª•ng ƒëi·ªán tho·∫°i', captureFrame());
            }
        } catch(e){}
    }

    // ============================================
    // 5. MAIN FLOW
    // ============================================
    async function main() {
        const cam = await setupCamera();
        if(!cam) { alert("L·ªói Camera! Kh√¥ng th·ªÉ gi√°m s√°t."); return; }
        
        const ai = await loadModels();
        if(!ai) return;

        // K√çCH HO·∫†T C√ÅC L√Å CH·∫ÆN B·∫¢O M·∫¨T (Quan tr·ªçng)
        setupSecurityListeners();

        startTimer();
        videoInterval = setInterval(detectFaces, CONFIG.face.detectionInterval);
        if(CONFIG.object.enabled) setInterval(detectObjects, CONFIG.object.scanInterval);
    }

    function startTimer() {
        let timeLeft = DURATION; // Bi·∫øn t·ª´ PHP
        const interval = setInterval(() => {
            timeLeft--;
            const m = Math.floor(timeLeft / 60).toString().padStart(2,'0');
            const s = (timeLeft % 60).toString().padStart(2,'0');
            timerElement.textContent = `${Math.floor(timeLeft/3600)}:${m}:${s}`;
            if(timeLeft <= 0) {
                clearInterval(interval);
                alert("H·∫øt gi·ªù!");
                testForm.submit();
            }
        }, 1000);
    }

    // --- Helpers ---
    function canLog(type) {
        if(window.isSubmitting) return false;
        const last = state.lastLogTime[type] || 0;
        if (Date.now() - last > CONFIG.logCooldown) {
            state.lastLogTime[type] = Date.now();
            return true;
        }
        return false;
    }

    function captureFrame() {
        try {
            const ctx = captureCanvas.getContext('2d');
            captureCanvas.width = webcamElement.videoWidth;
            captureCanvas.height = webcamElement.videoHeight;
            ctx.drawImage(webcamElement, 0, 0);
            return captureCanvas.toDataURL('image/jpeg', 0.7);
        } catch(e) { return null; }
    }

    // Events
    startButton.addEventListener('click', () => {
        document.documentElement.requestFullscreen().catch(e=>console.log(e));
        startOverlay.style.display = 'none';
        testContent.style.display = 'block';
        timerElement.style.display = 'block';
        proctoringContainer.style.display = 'block';
        main();
    });

    testForm.addEventListener('submit', () => { window.isSubmitting = true; });
});

// ============================================
// 6. GLOBAL FUNCTIONS (LOG & TOAST)
// ============================================

window.logCheating = async function(type, details, imageData) {
    if (window.isSubmitting) return;
    if (typeof ATTEMPT_ID === 'undefined') return;

    const formData = new FormData();
    formData.append('attempt_id', ATTEMPT_ID);
    formData.append('violation_type', type);
    formData.append('details', details);
    if (imageData) formData.append('screenshot', imageData);

    try {
        const res = await fetch('log_cheating.php', { method: 'POST', body: formData });
        if (res.ok) {
            const data = await res.json();
            if (data.status === 'suspended') {
                window.showSuspendedScreen(data.reason, data.total_violations);
                window.isSubmitting = true;
            } else if (data.status === 'warning') {
                window.showViolationToast(data.message, data.remaining, data.limit);
            }
        }
    } catch(e) { console.error(e); }
};

window.showViolationToast = function(msg, remaining, limit) {
    const container = document.getElementById('toast-container');
    if (!container) return;

    let conf = { color: 'border-amber-500', bg: 'bg-white', icon: '‚ö†Ô∏è', sub: '' };
    
    if (remaining < 0) { conf.sub = 'ƒê√£ ghi l·∫°i h√†nh vi.'; conf.color = 'border-blue-500'; }
    else if (remaining === 0) {
        conf.bg = 'bg-red-50'; conf.color = 'border-red-600'; conf.icon = '‚ò†Ô∏è';
        conf.sub = '<b class="text-red-700">C·∫¢NH B√ÅO CU·ªêI! (0 l·∫ßn)</b>';
    } else {
        conf.sub = `C√≤n <b class="text-orange-600">${remaining}</b>/${limit} l·∫ßn.`;
    }

    const toast = document.createElement('div');
    toast.className = `toast-enter pointer-events-auto w-full p-4 rounded-lg shadow-xl border-l-4 ${conf.color} ${conf.bg} flex items-start gap-3 mb-2 backdrop-blur-md relative`;
    toast.innerHTML = `
        <div class="mt-1 text-xl">${conf.icon}</div>
        <div class="flex-1">
            <h4 class="font-bold text-gray-800 text-sm uppercase">C·∫¢NH B√ÅO</h4>
            <p class="font-bold text-gray-900 text-sm mt-1">${msg}</p>
            <div class="text-xs mt-1 text-slate-600">${conf.sub}</div>
        </div>
        <button onclick="this.parentElement.remove()" class="absolute top-2 right-2 text-slate-400 hover:text-slate-600"><i class="fa-solid fa-xmark"></i></button>
    `;
    container.appendChild(toast);
    setTimeout(() => toast.remove(), 8000);
};

window.showSuspendedScreen = function(reason, count) {
    document.body.innerHTML = `
        <div style="position: fixed; inset: 0; background: #450a0a; color: white; display: flex; flex-direction: column; align-items: center; justify-content: center; font-family: sans-serif; text-align: center; z-index: 99999;">
            <div style="font-size: 80px; margin-bottom: 20px;">üö´</div>
            <h1 style="font-size: 32px; font-weight: bold; color: #fca5a5;">ƒê√åNH CH·ªà THI</h1>
            <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; max-width: 600px; margin-top: 20px;">
                <p style="font-size: 18px;">${reason}</p>
                <p style="font-size: 14px; color: #ccc; margin-top: 10px;">T·ªïng l·ªói: ${count}</p>
            </div>
            <a href="index.php" style="margin-top: 30px; background: white; color: #7f1d1d; text-decoration: none; padding: 12px 30px; border-radius: 8px; font-weight: bold;">V·ªÄ TRANG CH·ª¶</a>
        </div>
    `;
};